_target_: lightning.pytorch.trainer.Trainer

# default_root_dir: ${paths.output_dir}

min_epochs: 1 # prevents early stopping
max_epochs: ${max_epochs}

accelerator: cpu
devices: 1

# mixed precision for extra speed-up
# precision: 16

# perform a validation loop every N training epochs
check_val_every_n_epoch: ${check_val_every_n_epoch}

# set True to to ensure deterministic results
# makes training slower but gives more reproducibility than just setting seeds
deterministic: False

# Enable progress bar
enable_progress_bar: true

# Enable model checkpointing and add logger
logger:
  _target_: lightning.pytorch.loggers.TensorBoardLogger
  save_dir: "outputs"
  name: "flow_matching"

callbacks:
  - _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: "outputs/flow_matching/checkpoints"
    filename: "epoch={epoch:03d}-step={step}-val_loss={val_loss:.6f}"
    monitor: "val_loss"
    mode: "min"
    save_top_k: 3  # Keep 3 best checkpoints based on val_loss
    save_last: true  # Always save the last checkpoint
    every_n_epochs: 1  # Save every epoch
    save_on_train_epoch_end: false  # Save on validation end instead
  - _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: "val_loss"
    mode: "min"
    patience: 50  # Stop if val_loss doesn't improve for 50 epochs
    min_delta: 1e-6  # Minimum change to qualify as improvement
    verbose: true
