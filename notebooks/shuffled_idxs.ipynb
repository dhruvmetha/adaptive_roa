{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d127da58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded Humanoid bounds from: /common/users/dm1487/arcmg_datasets/humanoid_get_up/humanoid_data_bounds.pkl\n",
      "ðŸ“Š Per-Dimension Normalization Limits:\n",
      "\n",
      "   Euclidean Block 1 (dims 0-33):\n",
      "     [ 0]: Â±  0.859\n",
      "     [ 1]: Â±  1.375\n",
      "     [ 2]: Â±  0.725\n",
      "     [ 3]: Â±  0.526\n",
      "     [ 4]: Â±  0.633\n",
      "     ... (29 more dimensions)\n",
      "\n",
      "   Sphere (dims 34-36): NO NORMALIZATION (unit norm)\n",
      "\n",
      "   Euclidean Block 2 (dims 37-66):\n",
      "     [37]: Â±  1.914\n",
      "     [38]: Â±  1.916\n",
      "     [39]: Â±  3.328\n",
      "     [40]: Â±  2.790\n",
      "     [41]: Â±  2.940\n",
      "     ... (25 more dimensions)\n",
      "\n",
      "Loaded Humanoid bounds from: /common/users/dm1487/arcmg_datasets/humanoid_get_up/humanoid_data_bounds.pkl\n",
      "ðŸ“ Folder provided: /common/home/dm1487/robotics_research/tripods/olympics-classifier/outputs/humanoid_slow_reach/2025-11-02_23-19-45\n",
      "ðŸ” Searching for checkpoint in folder...\n",
      "   âœ“ Found best checkpoint (val_loss=0.0597)\n",
      "   ðŸ“„ Using: epoch110-val_loss0.0597.ckpt\n",
      "ðŸ¤– Loading Humanoid LCFM checkpoint: /common/home/dm1487/robotics_research/tripods/olympics-classifier/outputs/humanoid_slow_reach/2025-11-02_23-19-45/version_0/checkpoints/epoch110-val_loss0.0597.ckpt\n",
      "ðŸ“ Device: cuda:0\n",
      "ðŸ—‚ï¸  Training directory: /common/home/dm1487/robotics_research/tripods/olympics-classifier/outputs/humanoid_slow_reach/2025-11-02_23-19-45\n",
      "ðŸ“‹ Loading Hydra config: /common/home/dm1487/robotics_research/tripods/olympics-classifier/outputs/humanoid_slow_reach/2025-11-02_23-19-45/.hydra/config.yaml\n",
      "âœ… Hydra config loaded successfully\n",
      "ðŸ“¦ Loading Lightning checkpoint...\n",
      "âœ… Lightning checkpoint loaded\n",
      "ðŸ“‹ Config source: checkpoint (model_config)\n",
      "ðŸ“‹ Model config keys: ['_target_', 'embedded_dim', 'condition_dim', 'time_emb_dim', 'hidden_dims', 'output_dim', 'use_input_embeddings', 'input_emb_dim']\n",
      "ðŸ”§ Creating new Humanoid system (not found in hparams)\n",
      "   Using system config from Hydra config\n",
      "   bounds_file: /common/users/dm1487/arcmg_datasets/humanoid_get_up/humanoid_data_bounds.pkl\n",
      "   use_dynamic_bounds: True\n",
      "âœ… Loaded Humanoid bounds from: /common/users/dm1487/arcmg_datasets/humanoid_get_up/humanoid_data_bounds.pkl\n",
      "ðŸ“Š Per-Dimension Normalization Limits:\n",
      "\n",
      "   Euclidean Block 1 (dims 0-33):\n",
      "     [ 0]: Â±  0.859\n",
      "     [ 1]: Â±  1.375\n",
      "     [ 2]: Â±  0.725\n",
      "     [ 3]: Â±  0.526\n",
      "     [ 4]: Â±  0.633\n",
      "     ... (29 more dimensions)\n",
      "\n",
      "   Sphere (dims 34-36): NO NORMALIZATION (unit norm)\n",
      "\n",
      "   Euclidean Block 2 (dims 37-66):\n",
      "     [37]: Â±  1.914\n",
      "     [38]: Â±  1.916\n",
      "     [39]: Â±  3.328\n",
      "     [40]: Â±  2.790\n",
      "     [41]: Â±  2.940\n",
      "     ... (25 more dimensions)\n",
      "\n",
      "Loaded Humanoid bounds from: /common/users/dm1487/arcmg_datasets/humanoid_get_up/humanoid_data_bounds.pkl\n",
      "âœ… Initialized Humanoid CFM with Facebook Flow Matching:\n",
      "   - Manifold: â„Â³â´ Ã— SÂ² Ã— â„Â³â° (Euclidean Ã— Sphere Ã— Euclidean)\n",
      "   - Path: GeodesicProbPath with CondOTScheduler\n",
      "   - MAE validation frequency: every 10 epochs\n",
      "ðŸ”„ Loading model state dict...\n",
      "\n",
      "âœ… Model loaded successfully!\n",
      "   Checkpoint: epoch110-val_loss0.0597.ckpt\n",
      "   Config sources: Hydra + Lightning\n",
      "   System: HumanoidSystem\n",
      "   System bounds: Per-dimension (â„Â³â´ Ã— SÂ² Ã— â„Â³â°)\n",
      "   Model architecture: [256, 512, 1024, 1024, 512, 256]\n",
      "   Total parameters: 2,447,171\n",
      "   Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from src.systems.humanoid.system import HumanoidSystem\n",
    "from src.flow_matching.humanoid.latent_conditional.flow_matcher import HumanoidLatentConditionalFlowMatcher\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "data_dir = \"/common/users/shared/pracsys/genMoPlan/data_trajectories/humanoid_get_up_slow_reach\"\n",
    "roa_file = \"/common/users/shared/pracsys/genMoPlan/data_trajectories/humanoid_get_up_slow_reach/roa_labels.txt\"\n",
    "bounds_file = \"/common/users/dm1487/arcmg_datasets/humanoid_get_up/humanoid_data_bounds.pkl\"\n",
    "system = HumanoidSystem(bounds_file=bounds_file, use_dynamic_bounds=True, head_height_threshold=1.4, torso_z_threshold=0.9, speed_threshold=0.2)\n",
    "\n",
    "ckpt_path = \"/common/home/dm1487/robotics_research/tripods/olympics-classifier/outputs/humanoid_slow_reach/2025-11-02_23-19-45\"\n",
    "flow_matcher = HumanoidLatentConditionalFlowMatcher.load_from_checkpoint(ckpt_path, device=\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af8932a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4597333333333333"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roa_data = np.loadtxt(roa_file, delimiter=\",\")\n",
    "inp, labels = roa_data[:, :67], roa_data[:, 67]\n",
    "inp = torch.from_numpy(inp).float().to(\"cuda:0\")\n",
    "labels = torch.from_numpy(labels).long().to(\"cuda:0\")\n",
    "np.mean(roa_data[:, 67] == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7202ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# samples = 20\n",
    "# repeats = 1\n",
    "\n",
    "# tp = 0\n",
    "# tn = 0\n",
    "# fp = 0\n",
    "# fn = 0\n",
    "\n",
    "# # idx = 2049\n",
    "# for idx in tqdm(range(5, len(roa_data))):\n",
    "#     all_head_heights = []\n",
    "#     for _ in range(samples):\n",
    "#         model_input = inp[idx:idx+1, :].clone()\n",
    "#         head_height = []\n",
    "#         for i in range(repeats):\n",
    "#             pred = flow_matcher.predict_endpoint(model_input)\n",
    "#             head_height.append(pred[:, 21].item())\n",
    "#             model_input = pred.clone()\n",
    "#         all_head_heights.append(head_height)\n",
    "#     is_success = (sum(np.array(all_head_heights) > 1.3)/samples) > 0.5\n",
    "#     # print(sum(np.array(all_head_heights) > 1.3)/samples, is_success, labels[idx])\n",
    "#     if labels[idx] == 1 and is_success:\n",
    "#         tp += 1\n",
    "#     elif labels[idx] == 0 and is_success:\n",
    "#         fp += 1\n",
    "#     elif labels[idx] == 1 and not is_success:\n",
    "#         fn += 1\n",
    "#     elif labels[idx] == 0 and not is_success:\n",
    "#         tn += 1\n",
    "        \n",
    "#     if idx == 50:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fcfb5c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:55<00:00,  6.96s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "samples = 100\n",
    "repeats = 1\n",
    "batch_size = 2048  # You can tune this depending on memory\n",
    "success_threshold = 0.55\n",
    "failure_threshold = 0.45\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "sep_count = 0\n",
    "\n",
    "start_idx = 5\n",
    "stop_idx = len(roa_data)\n",
    "\n",
    "for batch_start in tqdm(range(start_idx, stop_idx, batch_size)):\n",
    "    batch_end = min(batch_start + batch_size, stop_idx)\n",
    "    batch_inp = inp[batch_start:batch_end, :]\n",
    "\n",
    "    # Will be (batch_size, samples, repeats)\n",
    "    all_head_heights = np.zeros((batch_end - batch_start, samples, repeats))\n",
    "\n",
    "    for sample_idx in range(samples):\n",
    "        model_input = batch_inp.clone()\n",
    "        for repeat_idx in range(repeats):\n",
    "            pred = flow_matcher.predict_endpoint(model_input)\n",
    "            # pred shape: (batch_size, d)\n",
    "            all_head_heights[:, sample_idx, repeat_idx] = pred[:, 21].detach().cpu().numpy()\n",
    "            model_input = pred.clone()\n",
    "\n",
    "    # Success logic: check along [samples, repeats] for each data point in batch\n",
    "    # We'll take the mean across all samples and repeats for head height > 1.3\n",
    "    mean_success = (all_head_heights > 1.3).mean(axis=(1,2))\n",
    "    is_success = mean_success > success_threshold  # shape: (batch_size,)\n",
    "    \n",
    "    is_failure = mean_success < failure_threshold  # shape: (batch_size,)\n",
    "    \n",
    "    sep_count += np.sum((mean_success <= success_threshold) & (mean_success >= failure_threshold))\n",
    "\n",
    "    batch_labels = labels[batch_start:batch_end].cpu().numpy()  # shape: (batch_size,)\n",
    "\n",
    "    tp += np.sum((batch_labels == 1) & (is_success))\n",
    "    fp += np.sum((batch_labels == 0) & (is_success))\n",
    "    fn += np.sum((batch_labels == 1) & (is_failure))\n",
    "    tn += np.sum((batch_labels == 0) & (is_failure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "48c91305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.480561122244489, Recall: 0.633051742344245, F1: 0.5463659147869674, Specificity: 0.39748953974895396, Sep: 0.73\n"
     ]
    }
   ],
   "source": [
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "specificity = tn / (tn + fp)\n",
    "sep_perc = sep_count/len(roa_data)\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}, Specificity: {specificity}, Sep: {sep_perc}\")\n",
    "\n",
    "# confusion matrix\n",
    "conf_mat = np.zeros((2, 2))\n",
    "conf_mat[0, 0] = tp\n",
    "conf_mat[0, 1] = fp\n",
    "conf_mat[1, 0] = fn\n",
    "conf_mat[1, 1] = tn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc2da8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3040., 3342.],\n",
       "       [1158., 1377.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4d1accc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 1012/15000 [00:07<01:47, 130.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 403\n",
      "Failure count: 597\n",
      "Success rate: 0.403\n",
      "Failure rate: 0.597\n",
      "Success lengths: 446.0\n",
      "Failure lengths: 436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 2012/15000 [00:15<01:39, 130.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 784\n",
      "Failure count: 1216\n",
      "Success rate: 0.392\n",
      "Failure rate: 0.608\n",
      "Success lengths: 446.0\n",
      "Failure lengths: 438.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 3017/15000 [00:23<01:33, 127.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 1166\n",
      "Failure count: 1834\n",
      "Success rate: 0.38866666666666666\n",
      "Failure rate: 0.6113333333333333\n",
      "Success lengths: 446.0\n",
      "Failure lengths: 441.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 4014/15000 [00:31<01:24, 130.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 1546\n",
      "Failure count: 2454\n",
      "Success rate: 0.3865\n",
      "Failure rate: 0.6135\n",
      "Success lengths: 446.0\n",
      "Failure lengths: 436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5023/15000 [00:39<01:16, 130.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 1922\n",
      "Failure count: 3078\n",
      "Success rate: 0.3844\n",
      "Failure rate: 0.6156\n",
      "Success lengths: 441.0\n",
      "Failure lengths: 436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6014/15000 [00:46<01:09, 130.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 2327\n",
      "Failure count: 3673\n",
      "Success rate: 0.3878333333333333\n",
      "Failure rate: 0.6121666666666666\n",
      "Success lengths: 441.0\n",
      "Failure lengths: 436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 7012/15000 [00:54<01:00, 131.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 2695\n",
      "Failure count: 4305\n",
      "Success rate: 0.385\n",
      "Failure rate: 0.615\n",
      "Success lengths: 441.0\n",
      "Failure lengths: 441.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8019/15000 [01:02<00:52, 132.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 3075\n",
      "Failure count: 4925\n",
      "Success rate: 0.384375\n",
      "Failure rate: 0.615625\n",
      "Success lengths: 441.0\n",
      "Failure lengths: 441.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9025/15000 [01:10<00:46, 127.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 3438\n",
      "Failure count: 5562\n",
      "Success rate: 0.382\n",
      "Failure rate: 0.618\n",
      "Success lengths: 441.0\n",
      "Failure lengths: 436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10017/15000 [01:17<00:38, 128.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 3807\n",
      "Failure count: 6193\n",
      "Success rate: 0.3807\n",
      "Failure rate: 0.6193\n",
      "Success lengths: 441.0\n",
      "Failure lengths: 436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11026/15000 [01:25<00:30, 131.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 4196\n",
      "Failure count: 6804\n",
      "Success rate: 0.38145454545454544\n",
      "Failure rate: 0.6185454545454545\n",
      "Success lengths: 441.0\n",
      "Failure lengths: 436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 12014/15000 [01:33<00:22, 132.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 4597\n",
      "Failure count: 7403\n",
      "Success rate: 0.38308333333333333\n",
      "Failure rate: 0.6169166666666667\n",
      "Success lengths: 441.0\n",
      "Failure lengths: 436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 13019/15000 [01:41<00:15, 128.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 5007\n",
      "Failure count: 7993\n",
      "Success rate: 0.3851538461538462\n",
      "Failure rate: 0.6148461538461538\n",
      "Success lengths: 441.0\n",
      "Failure lengths: 436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14023/15000 [01:48<00:07, 130.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 5388\n",
      "Failure count: 8612\n",
      "Success rate: 0.38485714285714284\n",
      "Failure rate: 0.6151428571428571\n",
      "Success lengths: 441.0\n",
      "Failure lengths: 436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15000/15000 [01:56<00:00, 128.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 5747\n",
      "Failure count: 9253\n",
      "Success rate: 0.3831333333333333\n",
      "Failure rate: 0.6168666666666667\n",
      "Success lengths: 441.0\n",
      "Failure lengths: 436.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "success_count = 0\n",
    "failure_count = 0\n",
    "success_lengths = []\n",
    "failure_lengths = []\n",
    "from tqdm import tqdm\n",
    "\n",
    "for file in tqdm(glob(os.path.join(data_dir, \"trajectories/*.txt\"))):\n",
    "    data = np.loadtxt(file, delimiter=\",\")\n",
    "    success = False\n",
    "    if system.is_in_attractor(data[-1:]).item():\n",
    "        success_count += 1\n",
    "        success_lengths.append(data.shape[0])\n",
    "    else:\n",
    "        failure_count += 1\n",
    "        failure_lengths.append(data.shape[0])\n",
    "        \n",
    "    if (success_count + failure_count) % 1000 == 0:\n",
    "        print(f\"Success count: {success_count}\")\n",
    "        print(f\"Failure count: {failure_count}\")\n",
    "        print(f\"Success rate: {success_count / (success_count + failure_count)}\")\n",
    "        print(f\"Failure rate: {failure_count / (success_count + failure_count)}\")\n",
    "        print(f\"Success lengths: {np.median(success_lengths)}\")\n",
    "        print(f\"Failure lengths: {np.median(failure_lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9242c1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success count: 5747\n",
      "Failure count: 9253\n",
      "Success rate: 0.3831333333333333\n",
      "Failure rate: 0.6168666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Success count: {success_count}\")\n",
    "print(f\"Failure count: {failure_count}\")\n",
    "print(f\"Success rate: {success_count / (success_count + failure_count)}\")\n",
    "print(f\"Failure rate: {failure_count / (success_count + failure_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27a6f10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success lengths: 192.0\n",
      "Failure lengths: 441.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Success lengths: {np.median(success_lengths)}\")\n",
    "print(f\"Failure lengths: {np.median(failure_lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae9e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
